{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import classification_data as cd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from random import randint\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "#from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Leitura da CNH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnh_aberta =  cd.readpath('dataset/CNH_Aberta/*')\n",
    "cnh_aberta =  cd.read_files(cnh_aberta)\n",
    "cnh_aberta = cd.resize_img(cnh_aberta,(50,50))\n",
    "\n",
    "cnh_frente =  cd.readpath('dataset/CNH_Frente/*')\n",
    "cnh_frente =  cd.read_files(cnh_frente)\n",
    "cnh_frente = cd.resize_img(cnh_frente,(50,50))\n",
    "\n",
    "cnh_verso =  cd.readpath('dataset/CNH_Verso/*')\n",
    "cnh_verso =  cd.read_files(cnh_verso)\n",
    "cnh_verso = cd.resize_img(cnh_verso,(50,50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Leitura do CPF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cpf_frente =  cd.readpath('dataset/CPF_Frente/*')\n",
    "cpf_frente =  cd.read_files(cpf_frente)\n",
    "cpf_frente = cd.resize_img(cpf_frente,(50,50))\n",
    "\n",
    "cpf_verso =  cd.readpath('dataset/CPF_Verso/*')\n",
    "cpf_verso =  cd.read_files(cpf_verso)\n",
    "cpf_verso = cd.resize_img(cpf_verso,(50,50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Leitura do RG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rg_frente =  cd.readpath('dataset/RG_Frente/*')\n",
    "rg_frente =  cd.read_files(rg_frente)\n",
    "rg_frente = cd.resize_img(rg_frente,(50,50))\n",
    "\n",
    "rg_verso =  cd.readpath('dataset/RG_Verso/*')\n",
    "rg_verso =  cd.read_files(rg_verso)\n",
    "rg_verso = cd.resize_img(rg_verso,(50,50))\n",
    "\n",
    "rg_aberto =  cd.readpath('dataset/RG_Aberto/*')\n",
    "rg_aberto =  cd.read_files(rg_aberto)\n",
    "rg_aberto = cd.resize_img(rg_aberto,(50,50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste de plotagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cnh_aberta[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Preparando os dados para o treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels = [1,2,3,4,5,6,7,8]\n",
    "documents = []\n",
    "\n",
    "for a,b,c,d,e,f,g,h in zip(cnh_aberta,cnh_frente,cnh_verso,cpf_frente,cpf_verso,rg_frente,rg_verso,rg_aberto):\n",
    "\tdocuments.append({'x':a, 'y':labels[0]})\n",
    "\tdocuments.append({'x':b,'y':labels[1]})\n",
    "\tdocuments.append({'x':c,'y':labels[2]})\n",
    "\tdocuments.append({'x':d,'y':labels[3]})\n",
    "\tdocuments.append({'x':e,'y':labels[4]})\n",
    "\tdocuments.append({'x':f,'y':labels[5]})\n",
    "\tdocuments.append({'x':g,'y':labels[6]})\n",
    "\tdocuments.append({'x':h,'y':labels[7]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "#{x,y},{x,y}, .....\n",
    "# 0,1,7,8,9\n",
    "for document in documents:\n",
    "\tif i < 1000:\n",
    "\t\tx_train.append(document['x'])\n",
    "\t\ty_train.append(document['y'])\n",
    "\telse: break\n",
    "\n",
    "i = 0\n",
    "\n",
    "np.random.shuffle(documents[1000:]) #embaralhando os documentos\n",
    "for document in documents[1000:]:\n",
    "\tif i < 1000:\n",
    "\t\tx_test.append(document['x'])\n",
    "\t\ty_test.append(document['y'])\n",
    "\telse: break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_train, y_train = cd.started_values(x_train,y_train)\n",
    "x_test, y_test = cd.started_values(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Iniciando o treinamento usando o modelo SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "document_classifier = SVC(kernel='linear')\n",
    "document_classifier.fit(x_train,y_train)\n",
    "\n",
    "test = random.choice(documents[1000:]) #escolhendo de forma aleatória\n",
    "\n",
    "prediction  = document_classifier.predict(test['x'].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Resultados do treinamento para SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Score:',document_classifier.score(x_train,y_train))\n",
    "print('Document:', cd.result(prediction))\n",
    "\n",
    "plt.imshow(test['x'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de Acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vizualizacao do modelo de accuraria\n",
    "\n",
    "#print('Accuracy:',metrics.accuracy_score(y_test[:1000],y_train[:1000]))\n",
    "\n",
    "plt.plot(y_test[:1000])\n",
    "plt.plot(y_train[:1000])\n",
    "plt.title(\"Modelo de Acurácia:\")\n",
    "plt.ylabel('Acurácia')\n",
    "plt.xlabel('Tempo')\n",
    "plt.legend(['Treinamento', 'Valor'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de Perda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vizulizacao do modelo de perda\n",
    "\n",
    "plt.plot(y_test[:1000])\n",
    "plt.plot(y_test[:1000])\n",
    "plt.title(\"Modelo de Perda:\")\n",
    "plt.ylabel('Perda')\n",
    "plt.xlabel('Tempo')\n",
    "plt.legend(['Treinamento', 'Valor'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rede Neural Convolucional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicializando a Rede Neural Convolucional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Primeira Camada de Convolução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertendo todas as imagens 64x64 pixels por um array 3d (3 cores)\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agrupando para diminuir o mapa das imagens\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionando a Segunda Camada de Convolução\n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agrupamento na segunda camada\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tecnica do achatamento tansanformando o map em um vetor\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Full connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Full connection -> juntando todo mundo \n",
    "relu -> ativação retificadora\n",
    "sigmoid -> probabilidade de certo de cada imagem \n",
    "'''\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compilando a rede\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinando a Rede Neural Convolucional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loding data\n",
    "from keras.datasets import cifar10\n",
    "#dividindo dataset em teste e treino\n",
    "(x_train,y_train), (x_test,y_test) = cifar10.load_data()\n",
    "#classificação \n",
    "classification = ['airplane','autombile','bird','cat','deer','dog','frog','house','ship','truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.load_img(cifar10, target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = classifier.predict(test_image)\n",
    "training_set.class_indices\n",
    "\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'Cachorro'\n",
    "else:\n",
    "    prediction = 'Gato'\n",
    "\n",
    "Image(filename='dataset_teste/2216.jpg')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a7f7bf6e294e5d2489f88d425ace11a197b461158df0335d6f5d57f2f7edadc8"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
