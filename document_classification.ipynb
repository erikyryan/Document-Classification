{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erikyryan/document-classification/blob/main/document_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pré-processamento dos dados\n",
        "\n",
        "Foram realizadas várias etapas de pré-processamento para garantir que os dados estivessem no formato correto. Primeiro, foi lida a base de dados e filtrados os arquivos pelo tipo desejado. Em seguida, foi alterado o tamanho das imagens para garantir que elas fossem compatíveis com os modelos. Por fim, foram preparados os dados para execução nos modelos.\n",
        "\n"
      ],
      "metadata": {
        "id": "6rL6HLsXh7wO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import das funções"
      ],
      "metadata": {
        "id": "4e4QGK5xBdz1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxhQ2v-t9CbZ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import requests\n",
        "import os\n",
        "import zipfile\n",
        "import glob\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from random import randint\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A função `process_images` filtra os arquivos permitindo que sejam selecionados somente os arquivos corretos para análise. A função recebe como parâmetro o filepath, que é o diretório do arquivo, e também o parâmetro size, contendo o formato das imagens desejado e um parâmetro para determinar a quantidade máxima de imagens que se deseja ter, tendo como padrão o valor de 3500. Isso pode variar conforme o que for informado."
      ],
      "metadata": {
        "id": "Prvb0noufeJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_images(filepath, size, max_files=3500):\n",
        "    filenames = []\n",
        "    readed_imgs = []\n",
        "    resized_imgs = []\n",
        "    i = 0\n",
        "\n",
        "    # Read file paths\n",
        "    for filename in glob.glob(filepath):\n",
        "        if ('segmentation' not in filename) and filename.endswith('.jpg') and i < max_files:\n",
        "            filenames.append(filename)\n",
        "            i += 1\n",
        "        else:\n",
        "            os.remove(filename)\n",
        "\n",
        "    for img in filenames:\n",
        "        readed_imgs.append(cv2.imread(img))\n",
        "\n",
        "    for img in readed_imgs:\n",
        "        resized_imgs.append(cv2.resize(img, size))\n",
        "\n",
        "    return resized_imgs\n",
        "\n",
        "#define os resultados para cada label\n",
        "def result(test):\n",
        "\tif test == 1 or test == 2 or test == 3:\n",
        "\t\treturn 'CNH'\n",
        "\telif test == 4 or test == 5:\n",
        "\t\treturn 'CPF'\n",
        "\telif test == 7 or test == 6 or test == 8:\n",
        "\t\treturn 'RG'\n",
        "\telse: return None"
      ],
      "metadata": {
        "id": "yLM2mQ9zLxZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "jZnfuGTA9Cbi"
      },
      "source": [
        "## Download e Extração das imagens de treinamento"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pathSample = 'https://drive.google.com/uc?id=144EqqmMtCziua9iYo-3afUEvZrJVxUXU&export=download&confirm=t&uuid=363cbdc1-ef8d-40e3-ac8f-92e8efbac4de&at=AKKF8vwO3Rerxp4Y4e7nvK22YqGB:1687737101639' #Database Sample\n",
        "compressionSamplePath = '/content/storage/sample.zip'\n",
        "sourcePath = '/content/storage'\n",
        "\n",
        "if not(os.path.isdir(sourcePath)):\n",
        "  os.mkdir('storage') #diretorio para armazenar os arquivos baixados."
      ],
      "metadata": {
        "id": "-tutGm7J9ONY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = requests.post(pathSample)\n",
        "\n",
        "with open(compressionSamplePath, 'wb') as file:\n",
        "    file.write(response.content)\n",
        "\n",
        "with zipfile.ZipFile(compressionSamplePath, 'r') as zip_ref:\n",
        "    zip_ref.extractall(sourcePath)\n"
      ],
      "metadata": {
        "id": "Inn0cjXz6Lvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Formatação dos documentos\n",
        "\n",
        "Realizando a chamada para cada grupo de imagem e formatado com o tamanho apropriedado"
      ],
      "metadata": {
        "id": "U29WgVaPWI6p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p95GH_f_9Cbl"
      },
      "outputs": [],
      "source": [
        "cnh_aberta =  process_images(sourcePath +'/BID Sample Dataset/CNH_Aberta/*', (256,256))\n",
        "cnh_frente =  process_images(sourcePath +'/BID Sample Dataset/CNH_Frente/*', (256,256))\n",
        "cnh_verso =  process_images(sourcePath +'/BID Sample Dataset/CNH_Verso/*', (256,256))\n",
        "\n",
        "cpf_frente =  process_images(sourcePath +'/BID Sample Dataset/CPF_Frente/*', (256,256))\n",
        "cpf_verso =  process_images(sourcePath +'/BID Sample Dataset/CPF_Verso/*', (256,256))\n",
        "\n",
        "rg_frente =  process_images(sourcePath +'/BID Sample Dataset/RG_Frente/*', (256,256))\n",
        "rg_verso =  process_images(sourcePath +'/BID Sample Dataset/RG_Verso/*', (256,256))\n",
        "rg_aberto =  process_images(sourcePath +'/BID Sample Dataset/RG_Aberto/*', (256,256))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "lBOmuzqP9Cbv"
      },
      "source": [
        "## Preparação dos dados para o treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nesta criamos uma list de dicionarios, devido o uso da funcao zip, ao finalizar garante que permanecera com um numero exato de documentos, para caso os arrays tenham tamanho diferente. Assim, facilitando a uniao de ambos."
      ],
      "metadata": {
        "id": "F2vjFII-iU9b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "2RloHJib9Cbw"
      },
      "outputs": [],
      "source": [
        "labels = [1,2,3,4,5,6,7,8]\n",
        "documents = []\n",
        "\n",
        "for a,b,c,d,e,f,g,h in zip(cnh_aberta,cnh_frente,cnh_verso,cpf_frente,cpf_verso,rg_frente,rg_verso,rg_aberto):\n",
        "\tdocuments.append({'x':a,'y':labels[0]})\n",
        "\tdocuments.append({'x':b,'y':labels[1]})\n",
        "\tdocuments.append({'x':c,'y':labels[2]})\n",
        "\tdocuments.append({'x':d,'y':labels[3]})\n",
        "\tdocuments.append({'x':e,'y':labels[4]})\n",
        "\tdocuments.append({'x':f,'y':labels[5]})\n",
        "\tdocuments.append({'x':g,'y':labels[6]})\n",
        "\tdocuments.append({'x':h,'y':labels[7]})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "GuWmo07B9Cbx"
      },
      "outputs": [],
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "x_test = []\n",
        "y_test = []\n",
        "\n",
        "np.random.shuffle(documents)\n",
        "\n",
        "x_train = [document['x'] for document in documents[:1000]]\n",
        "y_train = [document['y'] for document in documents[:1000]]\n",
        "\n",
        "x_test = np.array([document['x'] for document in documents[:2000]])\n",
        "y_test = np.array([document['y'] for document in documents[:2000]])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = [document['x'] for document in documents]\n",
        "y = [document['y'] for document in documents]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
        "\n",
        "x_train = np.array(x_train)\n",
        "n_samples = x_train.shape[0]\n",
        "x_train = x_train.reshape((n_samples, -1))\n",
        "\n",
        "x_test = np.array(x_test)\n",
        "n_samples = x_test.shape[0]\n",
        "x_test = x_test.reshape((n_samples, -1))\n",
        "\n",
        "y_test = np.array(y_test)\n",
        "y_train = np.array(y_train)\n"
      ],
      "metadata": {
        "id": "hF7H2QzLY4V3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "o-pn8xd_9Cby"
      },
      "source": [
        "# Modelo SVC\n",
        "\n",
        "SVC é a sigla para **Support Vector Classification**, que é um tipo de **Support Vector Machine (SVM)**, um algoritmo de aprendizado de máquina supervisionado que pode ser usado para desafios de classificação ou regressão. A principal diferença entre SVM e SVC é que se o hiperplano classifica o conjunto de dados linearmente, então o algoritmo é chamado de SVC e o algoritmo que separa o conjunto de dados por abordagem não linear é chamado de SVM.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svc = SVC(probability=True, kernel='linear')\n",
        "svc.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "EPMYub2HVMpD",
        "outputId": "57f5e007-6f22-4ef5-eedb-a541fc0ac094",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(kernel='linear', probability=True)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;, probability=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;, probability=True)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = svc.predict(x_test)\n",
        "y_pred_proba = svc.predict_proba(x_test)"
      ],
      "metadata": {
        "id": "k08VUyJ6WxK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "loss = log_loss(y_test, y_pred_proba)"
      ],
      "metadata": {
        "id": "wTu2si-2WlDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        },
        "id": "6jnfT62i9Cb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e67b983-54b6-43e7-fa64-97800df85f8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia: 0.95\n",
            "Perda Logarítmica: 0.34\n"
          ]
        }
      ],
      "source": [
        "print(f'Acurácia: {accuracy:.2f}')\n",
        "print(f'Perda Logarítmica: {loss:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRoor0669Cb4"
      },
      "source": [
        "# Rede neural convolucional"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Abaixo preparamos os dados alterando novamente o tamanho das imagens para o formato determinado, tanto para os valore de x, quanto para y."
      ],
      "metadata": {
        "id": "z7UCqisAFicU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(len(x_train),256, 256, 3)\n",
        "x_test = x_test.reshape(len(x_test), 256, 256, 3)\n",
        "y_test = y_test.reshape(len(y_test), 1)\n",
        "y_train = y_train.reshape(len(y_train), 1)"
      ],
      "metadata": {
        "id": "KNtfHVBJxI6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Criando um gerador de aumento de dados"
      ],
      "metadata": {
        "id": "6tHnCSwMf0wQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A função abaixo é usada para criar instâncias de geradores de imagem com transformações aleatórias. As transformações incluem rotação, mudança de largura e altura e espelhamento horizontal. Essas transformações são aplicadas aleatoriamente às imagens de entrada durante o treinamento do modelo para aumentar a quantidade de dados disponíveis e evitar o overfitting."
      ],
      "metadata": {
        "id": "pFFxrr0VF4Xh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True)"
      ],
      "metadata": {
        "id": "O19W5Ahif0AT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construindo o modelo\n",
        "\n",
        " O modelo tem duas camadas convolucionais com 32 e 64 filtros, respectivamente, seguidas por camadas de pooling e dropout. A camada densa tem 128 neurônios e a camada de saída tem apenas um neurônio com ativação softmax. O modelo é compilado com a função de perda binary_crossentropy e o otimizador Adam. Ele é usado para classificar imagens em duas classes."
      ],
      "metadata": {
        "id": "p_BZPJC5fvDA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wciHW4z09Cb8"
      },
      "outputs": [],
      "source": [
        "classifier = Sequential()\n",
        "classifier.add(Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)))\n",
        "classifier.add(MaxPooling2D((2, 2)))\n",
        "classifier.add(Dropout(0.25))\n",
        "\n",
        "classifier.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "classifier.add(MaxPooling2D((2, 2)))\n",
        "classifier.add(Dropout(0.25))\n",
        "\n",
        "classifier.add(Flatten())\n",
        "classifier.add(Dense(128, activation='relu'))\n",
        "classifier.add(Dropout(0.5))\n",
        "classifier.add(Dense(1, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compilando o modelo\n",
        "\n",
        "O código abaixo é usada para compilar o modelo. O parâmetro loss é a função de perda usada para otimizar o modelo. O parâmetro optimizer é o algoritmo de otimização usado para minimizar a função de perda. O parâmetro metrics é uma lista de métricas usadas para avaliar o desempenho do modelo durante o treinamento e teste. Nesse caso, a métrica usada é a acurácia."
      ],
      "metadata": {
        "id": "K4Jvp-YNfpPn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWeBiGWZ9Cb_"
      },
      "outputs": [],
      "source": [
        "classifier.compile( loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eawyx3C59Cb_"
      },
      "source": [
        "## Treinando a Rede Neural Convolucional"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O parâmetro **batch_size** é o número de amostras usadas em cada atualização do gradiente. O parâmetro **steps_per_epoch** é o número de lotes a serem extraídos do gerador de dados em cada época. O método fit() é usado para treinar o modelo com os dados gerados pelo datagen.flow(). Nesse caso, o modelo é treinado por 5 épocas."
      ],
      "metadata": {
        "id": "RnYXeza7gz18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "steps_per_epoch = len(x_train) // batch_size\n",
        "classifier.fit(datagen.flow(x_train, y_train, batch_size=batch_size), epochs=5, steps_per_epoch=steps_per_epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9S07X0-spjl",
        "outputId": "a97c3b28-342e-4201-9877-b5dfc241a41a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "3/3 [==============================] - 30s 9s/step - loss: 0.0000e+00 - accuracy: 0.1146\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 30s 9s/step - loss: 0.0000e+00 - accuracy: 0.1042\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 25s 7s/step - loss: 0.0000e+00 - accuracy: 0.0850\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 26s 7s/step - loss: 0.0000e+00 - accuracy: 0.1176\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 25s 7s/step - loss: 0.0000e+00 - accuracy: 0.1176\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f47c8f412a0>"
            ]
          },
          "metadata": {},
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esse trecho de código é usado para avaliar o desempenho do modelo em um conjunto de dados de teste. O método evaluate() é usado para avaliar o modelo com os dados de teste x_test e y_test. Ele retorna a perda e a acurácia do modelo nos dados de teste. Esses valores são impressos na tela usando o comando print()."
      ],
      "metadata": {
        "id": "NuILSuIRLxMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = classifier.evaluate(x_test, y_test)\n",
        "print(\"Acurácia: \", acc)\n",
        "print(\"valor de perda: \",loss)"
      ],
      "metadata": {
        "id": "cnc_5Alpozqt",
        "outputId": "79de11e9-8322-4b14-f3a6-1a7a00f68439",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 2s 692ms/step - loss: 0.0000e+00 - accuracy: 0.1818\n",
            "Acurácia:  0.1818181872367859\n",
            "valor de perda:  0.0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "a7f7bf6e294e5d2489f88d425ace11a197b461158df0335d6f5d57f2f7edadc8"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "document_classification.ipynb",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}